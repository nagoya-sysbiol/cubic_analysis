{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "67c75f06",
      "metadata": {
        "id": "67c75f06"
      },
      "source": [
        "# Convert tiff files to hdf5 file (for ilastik analysis)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "43fb5a35",
      "metadata": {
        "id": "43fb5a35"
      },
      "outputs": [],
      "source": [
        "# import necessary libraries\n",
        "\n",
        "import tifffile\n",
        "import glob\n",
        "import h5py\n",
        "import os\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "ff035c54",
      "metadata": {
        "id": "ff035c54"
      },
      "outputs": [],
      "source": [
        "def load_tiff_sequence ( imdir, imgtype='tiff', range=None ):\n",
        "    \"\"\"\n",
        "    load tiff sequence stored in the same directory\n",
        "    e.g. \n",
        "    vol = load_tiff_sequence (imgdir, '.png', range=[])\n",
        "    \"\"\"\n",
        "\n",
        "    imlist = glob.glob( imdir + '*.' + imgtype )\n",
        "    imlist.sort() # sort numerically\n",
        "    \n",
        "    if range is not None:\n",
        "        imlist = imlist[ range[0]:range[1]]\n",
        "        \n",
        "    #get image properties by reading the first image\n",
        "    im = tifffile.imread(imlist[0])\n",
        "    imsize_x = im.shape[1]\n",
        "    imsize_y = im.shape[0]\n",
        "    imsize_z = len( imlist )\n",
        "    imsize = ( imsize_z, imsize_y, imsize_x )\n",
        "    imtype = im.dtype\n",
        "    \n",
        "    stack = np.zeros( imsize, dtype=imtype )\n",
        "    for (i, impath) in enumerate(imlist):\n",
        "        im = tifffile.imread( impath )\n",
        "        stack[i,:,:] = im\n",
        "        \n",
        "    return stack"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "e96388ef",
      "metadata": {
        "id": "e96388ef"
      },
      "outputs": [],
      "source": [
        "def write_as_hdf5( stack, h5name, destname, \n",
        "                   chunks_enabled=True, chunksize=None,\n",
        "                   attributes=None ):\n",
        "    \"\"\"\n",
        "    e.g.\n",
        "    write_as_hdf5(vol, 'test.hdf5', 'resolution_0', True, (100,100,100))\n",
        "    \"\"\"\n",
        "    if chunks_enabled:\n",
        "        if chunksize is None:\n",
        "            chunks = True\n",
        "        else:\n",
        "            chunks = chunksize\n",
        "    else:\n",
        "        chunks = None\n",
        "        \n",
        "    with h5py.File( h5name, 'w', driver='stdio' ) as hf:\n",
        "        data = hf.create_dataset (destname,\n",
        "                                  chunks=chunks,\n",
        "                                  data=stack )\n",
        "        if attributes is not None:\n",
        "            for key, value in attributes.items():\n",
        "                data.attrs[key] = value"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Download\n",
        "# !wget https://www.dropbox.com/s/fuj2ndxzoijgy2n/190604_%23144_lung_raw_tiff.zip\n",
        "!wget https://www.dropbox.com/s/3n88u2pvh7i60zw/190604_P_%23144_lung_ctrl_x125_639_Probabilities.h5\n",
        "# !wget https://www.dropbox.com/s/ftt9ebiayn5fi8i/190604_P_%23144_lung_ctrl_x125_639.hdf5\n",
        "\n",
        "# ! unzip 190604_#144_lung_raw_tiff_10slices.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dqbh8CUi2627",
        "outputId": "c415ad86-cadb-4cb7-dd11-b549b46644fa"
      },
      "id": "Dqbh8CUi2627",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-08-10 05:20:35--  https://www.dropbox.com/s/3n88u2pvh7i60zw/190604_P_%23144_lung_ctrl_x125_639_Probabilities.h5\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.4.18, 2620:100:601d:18::a27d:512\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.4.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/3n88u2pvh7i60zw/190604_P_%23144_lung_ctrl_x125_639_Probabilities.h5 [following]\n",
            "--2022-08-10 05:20:35--  https://www.dropbox.com/s/raw/3n88u2pvh7i60zw/190604_P_%23144_lung_ctrl_x125_639_Probabilities.h5\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc0571f10e6e6c06042d6bab71fd.dl.dropboxusercontent.com/cd/0/inline/Bqtu79dU2graITP4hVf-8w3KLT4LHDn6Nbyo9_le1s7_ZrlORC5KIIHByT0dLAgQm4zD9d-DJdKWatjvAHZ1T-w0m5CnBAJYZmjeLnZZ9V8HSMzuv6DTRzOqUbJY8CBLZlZmbaGDl_b_gJsyyvWW3ox8muvsJwQ6Q98e9ogcF-pySA/file# [following]\n",
            "--2022-08-10 05:20:36--  https://uc0571f10e6e6c06042d6bab71fd.dl.dropboxusercontent.com/cd/0/inline/Bqtu79dU2graITP4hVf-8w3KLT4LHDn6Nbyo9_le1s7_ZrlORC5KIIHByT0dLAgQm4zD9d-DJdKWatjvAHZ1T-w0m5CnBAJYZmjeLnZZ9V8HSMzuv6DTRzOqUbJY8CBLZlZmbaGDl_b_gJsyyvWW3ox8muvsJwQ6Q98e9ogcF-pySA/file\n",
            "Resolving uc0571f10e6e6c06042d6bab71fd.dl.dropboxusercontent.com (uc0571f10e6e6c06042d6bab71fd.dl.dropboxusercontent.com)... 162.125.4.15, 2620:100:601d:15::a27d:50f\n",
            "Connecting to uc0571f10e6e6c06042d6bab71fd.dl.dropboxusercontent.com (uc0571f10e6e6c06042d6bab71fd.dl.dropboxusercontent.com)|162.125.4.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5309363880 (4.9G) [text/plain]\n",
            "Saving to: ‘190604_P_#144_lung_ctrl_x125_639_Probabilities.h5’\n",
            "\n",
            "190604_P_#144_lung_ 100%[===================>]   4.94G  68.6MB/s    in 97s     \n",
            "\n",
            "2022-08-10 05:22:13 (52.3 MB/s) - ‘190604_P_#144_lung_ctrl_x125_639_Probabilities.h5’ saved [5309363880/5309363880]\n",
            "\n",
            "unzip:  cannot find or open 190604_#144_lung_raw_tiff_10slices.zip, 190604_#144_lung_raw_tiff_10slices.zip.zip or 190604_#144_lung_raw_tiff_10slices.zip.ZIP.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "7b6ce507",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7b6ce507",
        "outputId": "865fa0e0-f712-4fc6-a791-ede558ac9a33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/190604_#144_lung_raw_tiff_10slices\n",
            "(10, 2160, 2560)\n"
          ]
        }
      ],
      "source": [
        "#Choose Tiff file folder\n",
        "os.chdir(\"/content/190604_#144_lung_raw_tiff_10slices\")\n",
        "print(os.getcwd())\n",
        "\n",
        "#Read Tiff file\n",
        "imgdir = \"/content/190604_#144_lung_raw_tiff_10slices//\"\n",
        "img = load_tiff_sequence( imgdir, imgtype='tiff')\n",
        "\n",
        "print(img.shape)\n",
        "\n",
        "#Save as hdf5\n",
        "filename = \"/content/190604_P_#144_lung_ctrl_x125_639_10slices.hdf5\"\n",
        "dname = \"content\"\n",
        "\n",
        "write_as_hdf5( img, filename, dname, chunks_enabled=True, chunksize=(10,100,100) )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c2660bb2",
      "metadata": {
        "id": "c2660bb2"
      },
      "source": [
        "# probability threshold (after ilastik analysis)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "350243f0",
      "metadata": {
        "id": "350243f0"
      },
      "outputs": [],
      "source": [
        "# import necessary libraries\n",
        "import tifffile\n",
        "import glob\n",
        "import h5py\n",
        "import os\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "f62c5f01",
      "metadata": {
        "id": "f62c5f01"
      },
      "outputs": [],
      "source": [
        "def load_tiff_sequence ( imdir, imgtype='tiff', range=None ):\n",
        "    \"\"\"\n",
        "    load tiff sequence stored in the same directory\n",
        "    e.g. \n",
        "    vol = load_tiff_sequence (imgdir, '.png', range=[])\n",
        "    \"\"\"\n",
        "\n",
        "    imlist = glob.glob( imdir + '*.' + imgtype )\n",
        "    imlist.sort() # sort numerically\n",
        "    \n",
        "    if range is not None:\n",
        "        imlist = imlist[ range[0]:range[1]]\n",
        "        \n",
        "    #get image properties by reading the first image\n",
        "    im = tifffile.imread(imlist[0])\n",
        "    imsize_x = im.shape[1]\n",
        "    imsize_y = im.shape[0]\n",
        "    imsize_z = len( imlist )\n",
        "    imsize = ( imsize_z, imsize_y, imsize_x )\n",
        "    imtype = im.dtype\n",
        "    \n",
        "    stack = np.zeros( imsize, dtype=imtype )\n",
        "    for (i, impath) in enumerate(imlist):\n",
        "        im = tifffile.imread( impath )\n",
        "        stack[i,:,:] = im\n",
        "        \n",
        "    return stack"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "38ab0e43",
      "metadata": {
        "id": "38ab0e43"
      },
      "outputs": [],
      "source": [
        "def write_as_hdf5( stack, h5name, destname, \n",
        "                   chunks_enabled=True, chunksize=None,\n",
        "                   attributes=None ):\n",
        "    \"\"\"\n",
        "    e.g.\n",
        "    write_as_hdf5(vol, 'test.hdf5', 'resolution_0', True, (100,100,100))\n",
        "    \"\"\"\n",
        "    if chunks_enabled:\n",
        "        if chunksize is None:\n",
        "            chunks = True\n",
        "        else:\n",
        "            chunks = chunksize\n",
        "    else:\n",
        "        chunks = None\n",
        "        \n",
        "    with h5py.File( h5name, 'w', driver='stdio' ) as hf:\n",
        "        data = hf.create_dataset (destname,\n",
        "                                  chunks=chunks,\n",
        "                                  data=stack )\n",
        "        if attributes is not None:\n",
        "            for key, value in attributes.items():\n",
        "                data.attrs[key] = value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "87aa710e",
      "metadata": {
        "id": "87aa710e"
      },
      "outputs": [],
      "source": [
        "h5name = \"/content/190604_P_#144_lung_ctrl_x125_639_Probabilities_10slices.h5\"\n",
        "hf = h5py.File( h5name, \"r\" )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = hf[\"expmat\"]\n",
        "print (data.shape)\n",
        "l1_prob = data[:,:,:,0] # probability of label1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "siTkiqKVEX9v",
        "outputId": "dc2e6efb-edac-4a85-9342-bc7107726936"
      },
      "id": "siTkiqKVEX9v",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10, 2160, 2560, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "c9e6127a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9e6127a",
        "outputId": "ffe6b942-3a5b-4e38-ae63-aa78e5f1a6e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "165508942.5\n"
          ]
        }
      ],
      "source": [
        "# maks a binary mask\n",
        "binary24 = (l1_prob > 24)\n",
        "print (binary24.sum()*8.25*8.25*10)\n",
        "# make binary into uint8\n",
        "binary24 = (255*binary24).astype( 'uint16' )\n",
        "# export as tiff\n",
        "filename = \"/content/190604_P_#144_lung_ctrl_x125_639_bin10A.tiff\"\n",
        "tifffile.imsave( filename, binary24 )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "1ab4c874",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ab4c874",
        "outputId": "d32417ff-fccd-4871-8e09-af00782a6ea5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "133056061.875\n"
          ]
        }
      ],
      "source": [
        "# maks a binary mask\n",
        "binary50 = (l1_prob > 50)\n",
        "print (binary50.sum()*8.25*8.25*10)\n",
        "# make binary into uint8\n",
        "binary50 = (255*binary50).astype( 'uint16' )\n",
        "# export as tiff\n",
        "filename = \"/content/190604_P_#144_lung_ctrl_x125_639_bin20B.tiff\"\n",
        "tifffile.imsave( filename, binary50 )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "3f5d4535",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3f5d4535",
        "outputId": "4c17c9f7-2b36-4be2-bd9e-cc2371a5e982"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "119030422.5\n"
          ]
        }
      ],
      "source": [
        "# maks a binary mask\n",
        "binary75 = (l1_prob > 75)\n",
        "print (binary75.sum()*8.25*8.25*10)\n",
        "# make binary into uint8\n",
        "binary75 = (255*binary75).astype( 'uint16' )\n",
        "# export as tiff\n",
        "filename = \"/content/190604_P_#144_lung_ctrl_x125_639_bin30C.tiff\"\n",
        "tifffile.imsave( filename, binary75 )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "2f7db4f8",
      "metadata": {
        "id": "2f7db4f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81528666-dff1-4ad7-fe6e-92367f193363"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "103172540.625\n"
          ]
        }
      ],
      "source": [
        "# maks a binary mask\n",
        "binary101 = (l1_prob > 101)\n",
        "print (binary101.sum()*8.25*8.25*10)\n",
        "# make binary into uint8\n",
        "binary101 = (255*binary101).astype( 'uint16' )\n",
        "# export as tiff\n",
        "filename = \"/content/190604_P_#144_lung_ctrl_x125_639_bin40D.tiff\"\n",
        "tifffile.imsave( filename, binary101 )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "f32ec412",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f32ec412",
        "outputId": "5e62e619-b0f4-4ca9-db93-7f6211400d91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "85788016.875\n"
          ]
        }
      ],
      "source": [
        "# maks a binary mask\n",
        "binary126 = (l1_prob > 126)\n",
        "print (binary126.sum()*8.25*8.25*10)\n",
        "# make binary into uint8\n",
        "binary126 = (255*binary126).astype( 'uint16' )\n",
        "# export as tiff\n",
        "filename = \"/content/190604_P_#144_lung_ctrl_x125_639_bin50E.tiff\"\n",
        "tifffile.imsave( filename, binary126 )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "b9de8616",
      "metadata": {
        "id": "b9de8616",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "151c0d23-7de2-4365-96ff-52f40179f1d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "72314364.375\n"
          ]
        }
      ],
      "source": [
        "# maks a binary mask\n",
        "binary152 = (l1_prob > 152)\n",
        "print (binary152.sum()*8.25*8.25*10)\n",
        "# make binary into uint8\n",
        "binary152 = (255*binary152).astype( 'uint16' )\n",
        "# export as tiff\n",
        "filename = \"/content/190604_P_#144_lung_ctrl_x125_639_bin60F.tiff\"\n",
        "tifffile.imsave( filename, binary152 )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "4ebffa87",
      "metadata": {
        "id": "4ebffa87",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f430e48-227d-47b0-d22c-6f1431f88e3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "59966465.625\n"
          ]
        }
      ],
      "source": [
        "# maks a binary mask\n",
        "binary178 = (l1_prob > 178)\n",
        "print (binary178.sum()*8.25*8.25*10)\n",
        "# make binary into uint8\n",
        "binary178 = (255*binary178).astype( 'uint16' )\n",
        "# export as tiff\n",
        "filename = \"/content/190604_P_#144_lung_ctrl_x125_639_bin70G.tiff\"\n",
        "tifffile.imsave( filename, binary178 )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "29487e1d",
      "metadata": {
        "id": "29487e1d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac67f518-3377-460d-afe6-b9a2626e9015"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "49488243.75\n"
          ]
        }
      ],
      "source": [
        "# maks a binary mask\n",
        "binary203 = (l1_prob > 203)\n",
        "print (binary203.sum()*8.25*8.25*10)\n",
        "# make binary into uint8\n",
        "binary203 = (255*binary203).astype( 'uint16' )\n",
        "# export as tiff\n",
        "filename = \"/content/190604_P_#144_lung_ctrl_x125_639_bin80H.tiff\"\n",
        "tifffile.imsave( filename, binary203 )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "6798a327",
      "metadata": {
        "id": "6798a327",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d137db25-7a05-4da5-9312-fa75c996b415"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "33390781.875\n"
          ]
        }
      ],
      "source": [
        "# maks a binary mask\n",
        "binary229 = (l1_prob > 229)\n",
        "print (binary229.sum()*8.25*8.25*10)\n",
        "# make binary into uint8\n",
        "binary229 = (255*binary229).astype( 'uint16' )\n",
        "# export as tiff\n",
        "filename = \"/content/190604_P_#144_lung_ctrl_x125_639_bin90I.tiff\"\n",
        "tifffile.imsave( filename, binary229 )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0b7d394e",
      "metadata": {
        "id": "0b7d394e"
      },
      "source": [
        "# Count all signal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "61d34cb8",
      "metadata": {
        "id": "61d34cb8"
      },
      "outputs": [],
      "source": [
        "# import necessary libraries\n",
        "# from skimage.external import tifffile # Error, use tifffile library\n",
        "import tifffile\n",
        "from scipy.ndimage import label\n",
        "from matplotlib import pyplot as plt\n",
        "import pandas as pd\n",
        "import scipy.ndimage as ndi\n",
        "import glob\n",
        "import h5py\n",
        "import os\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "eb8e45e2",
      "metadata": {
        "id": "eb8e45e2"
      },
      "outputs": [],
      "source": [
        "def load_tiff_sequence ( imdir, imgtype='tiff', range=None ):\n",
        "    \"\"\"\n",
        "    load tiff sequence stored in the same directory\n",
        "    e.g. \n",
        "    vol = load_tiff_sequence (imgdir, '.png', range=[])\n",
        "    \"\"\"\n",
        "\n",
        "    imlist = glob.glob( imdir + '*.' + imgtype )\n",
        "    imlist.sort() # sort numerically\n",
        "    \n",
        "    if range is not None:\n",
        "        imlist = imlist[ range[0]:range[1]]\n",
        "        \n",
        "    #get image properties by reading the first image\n",
        "    im = tifffile.imread(imlist[0])\n",
        "    imsize_x = im.shape[1]\n",
        "    imsize_y = im.shape[0]\n",
        "    imsize_z = len( imlist )\n",
        "    imsize = ( imsize_z, imsize_y, imsize_x )\n",
        "    imtype = im.dtype\n",
        "    \n",
        "    stack = np.zeros( imsize, dtype=imtype )\n",
        "    for (i, impath) in enumerate(imlist):\n",
        "        im = tifffile.imread( impath )\n",
        "        stack[i,:,:] = im\n",
        "        \n",
        "    return stack"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "22e92c5b",
      "metadata": {
        "id": "22e92c5b"
      },
      "outputs": [],
      "source": [
        "def write_as_hdf5( stack, h5name, destname, \n",
        "                   chunks_enabled=True, chunksize=None,\n",
        "                   attributes=None ):\n",
        "    \"\"\"\n",
        "    e.g.\n",
        "    write_as_hdf5(vol, 'test.hdf5', 'resolution_0', True, (100,100,100))\n",
        "    \"\"\"\n",
        "    if chunks_enabled:\n",
        "        if chunksize is None:\n",
        "            chunks = True\n",
        "        else:\n",
        "            chunks = chunksize\n",
        "    else:\n",
        "        chunks = None\n",
        "        \n",
        "    with h5py.File( h5name, 'w', driver='stdio' ) as hf:\n",
        "        data = hf.create_dataset (destname,\n",
        "                                  chunks=chunks,\n",
        "                                  data=stack )\n",
        "        if attributes is not None:\n",
        "            for key, value in attributes.items():\n",
        "                data.attrs[key] = value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "9e2d8c89",
      "metadata": {
        "id": "9e2d8c89"
      },
      "outputs": [],
      "source": [
        "def ask_hdf5_size( h5name, dsetname=None ):\n",
        "    \n",
        "    # obtain file handle\n",
        "    hf = h5py.File( h5name, 'r' )\n",
        "    \n",
        "    if dsetname is None:\n",
        "        # get the name of the 0th dataset\n",
        "        dsetname = list( hf.keys() )[0]\n",
        "        dset = hf[ dsetname ]\n",
        "    else:\n",
        "        # get dataset\n",
        "        dset = hf[ dsetname ]\n",
        "    \n",
        "    # print size\n",
        "    print( \"Data set size:\", dset.shape )\n",
        "    \n",
        "    # close handle\n",
        "    hf.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "96b8d39e",
      "metadata": {
        "id": "96b8d39e"
      },
      "outputs": [],
      "source": [
        "def load_hdf5( h5name, dsetname=None, multichannel=True ):\n",
        "    \n",
        "    # obtain file handle\n",
        "    hf = h5py.File( h5name, 'r' )\n",
        "    \n",
        "    if dsetname is None:\n",
        "        # get the name of the 0th dataset\n",
        "        dsetname = list( hf.keys() )[0]\n",
        "        dset = hf[ dsetname ]\n",
        "    else:\n",
        "        # get dataset\n",
        "        dset = hf[ dsetname ]\n",
        "    \n",
        "    if multichannel:\n",
        "        # load data as numpy array\n",
        "        data = dset[ :, :, :, 0] # 0th channel = cells\n",
        "        #data = dset[ :, :, :, 0] # 0th channel = cells\n",
        "    else:\n",
        "        data = dset[ :, :, :] # 0th channel = cells\n",
        "        #data = dset[ :, :, :] # 0th channel = cells\n",
        "\n",
        "    # close handle\n",
        "    hf.close()\n",
        "    \n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "6d50b613",
      "metadata": {
        "id": "6d50b613"
      },
      "outputs": [],
      "source": [
        "def calculate_prob_hdf5(file_list, threshold):\n",
        "    \n",
        "    # load probabiltiy image\n",
        "    prob = load_hdf5( file, \"expmat\", multichannel=True )\n",
        "    print (prob.shape)\n",
        "    \n",
        "    ### Binarize probability image\n",
        "    thresh = threshold * 255\n",
        "    binary = ( prob > thresh )\n",
        "    print (\"Total volume of detected signals:\", binary.sum()*8.25*8.25*10)\n",
        "    \n",
        "    # this defines \"connectivity\" between voxels\n",
        "    # structure = ndi.generate_binary_structure( 3, 3 )\n",
        "    \n",
        "    # this defines \"connectivity\" between voxels\n",
        "    structure = np.array( [[[0,0,0],\n",
        "                            [0,0,0],\n",
        "                           [0,0,0]],\n",
        "                           [[0,0,0],\n",
        "                            [0,0,0],\n",
        "                            [0,0,0]],\n",
        "                           [[0,0,0],\n",
        "                            [0,0,0],\n",
        "                            [0,0,0]]])\n",
        "        \n",
        "    # Label isolated objects\n",
        "    objects, num_objects = label( binary, structure )\n",
        "    print( \"Number of detected objects:\", objects.max() )\n",
        "        \n",
        "    # make binary into uint16\n",
        "    binary16 = (255*binary).astype( 'uint16' )\n",
        "    \n",
        "    # export as tiff\n",
        "    #basename = os.path.basename(file)\n",
        "    #filename = rootdir[:-5] + \"tiff/\" + basename[:-4] + \".tif\"\n",
        "    #tifffile.imsave( filename, binary16 )\n",
        "    \n",
        "    ### Find center of mass\n",
        "    ids = np.arange( 1, num_objects+1 )\n",
        "    coms = ndi.center_of_mass( binary, objects, ids )\n",
        "    \n",
        "    # convert to numpy array\n",
        "    coms = np.array( coms )\n",
        "    \n",
        "    # Compute volume of each object\n",
        "    unique, counts = np.unique( objects, return_counts=True )\n",
        "    # remove 0\n",
        "    unique = unique[1:]\n",
        "    counts = counts[1:]\n",
        "    \n",
        "    # create empty dataframe\n",
        "    df = pd.DataFrame()\n",
        "    \n",
        "    # colum \"ID\"\n",
        "    df['ID'] = unique\n",
        "    \n",
        "    # column \"X\", \"Y\", \"Z\"\n",
        "    df['X'] = coms[ :, 2 ]\n",
        "    df['Y'] = coms[ :, 1 ]\n",
        "    df['Z'] = coms[ :, 0 ]\n",
        "    \n",
        "    # colum \"volume\"\n",
        "    df[\"volume\"] = counts\n",
        "    \n",
        "    # save as csv\n",
        "    basename = os.path.basename(file)\n",
        "    csvdir = rootdir + \"csv\"\n",
        "    if not os.path.exists(csvdir):\n",
        "      os.mkdir(csvdir)\n",
        "    filename = rootdir + \"csv/\" + basename[:-26] + f\"_p{int(threshold*100)}_all_639.csv\"\n",
        "    df.to_csv( filename, index=False, float_format='%.2f' )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "bc2b2c2a",
      "metadata": {
        "id": "bc2b2c2a"
      },
      "outputs": [],
      "source": [
        "# Define root diretory\n",
        "rootdir = \"/content/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "9c9f38c6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9c9f38c6",
        "outputId": "4efc439d-4a79-409b-d5b4-af4be8f3db36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['/content/190604_P_#144_lung_ctrl_x125_639_Probabilities_10slices.h5']\n"
          ]
        }
      ],
      "source": [
        "# get files which ends with 'probability'\n",
        "file_list = glob.glob( rootdir + \"*_Probabilities_10slices.h5\" )\n",
        "print( file_list )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file = file_list[0]\n",
        "prob = load_hdf5( file, \"expmat\", multichannel=False )"
      ],
      "metadata": {
        "id": "-lGLhY7DGom6"
      },
      "id": "-lGLhY7DGom6",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "3176aea9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3176aea9",
        "outputId": "6712d309-15c9-49ab-b29e-e5a820dc5e2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data set size: (10, 2160, 2560, 2)\n",
            "190604_P_#144_lung_ctrl_x125_639_Probabilities_10slices\n",
            "(10, 2160, 2560)\n",
            "Total volume of detected signals: 160266768.75\n",
            "Number of detected objects: 235470\n",
            "Data set size: (10, 2160, 2560, 2)\n",
            "190604_P_#144_lung_ctrl_x125_639_Probabilities_10slices\n",
            "(10, 2160, 2560)\n",
            "Total volume of detected signals: 117569120.625\n",
            "Number of detected objects: 172737\n",
            "Data set size: (10, 2160, 2560, 2)\n",
            "190604_P_#144_lung_ctrl_x125_639_Probabilities_10slices\n",
            "(10, 2160, 2560)\n",
            "Total volume of detected signals: 84283835.625\n",
            "Number of detected objects: 123833\n",
            "Data set size: (10, 2160, 2560, 2)\n",
            "190604_P_#144_lung_ctrl_x125_639_Probabilities_10slices\n",
            "(10, 2160, 2560)\n",
            "Total volume of detected signals: 59966465.625\n",
            "Number of detected objects: 88105\n",
            "Data set size: (10, 2160, 2560, 2)\n",
            "190604_P_#144_lung_ctrl_x125_639_Probabilities_10slices\n",
            "(10, 2160, 2560)\n",
            "Total volume of detected signals: 33390781.875\n",
            "Number of detected objects: 49059\n"
          ]
        }
      ],
      "source": [
        "# loop through all files and thresholds\n",
        "thresholds = [0.1, 0.3, 0.5, 0.7, 0.9]\n",
        "for file in file_list:\n",
        "    for thresh in thresholds:\n",
        "      ask_hdf5_size( file, dsetname=None )\n",
        "      raw = load_hdf5(file, multichannel=False)\n",
        "      print (file.rsplit(\"/\")[-1][:-3])\n",
        "      calculate_prob_hdf5(file, thresh)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f916299f",
      "metadata": {
        "id": "f916299f"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "Signal extraction 10slices.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}